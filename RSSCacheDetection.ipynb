{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><b>RSS Cache Detection Challenge</b></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Normal publish times**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# define path where the csv files are stored\n",
    "path = r\"YourFilepath\\RSSCacheDetection\\ACCOUNT_ARTICLE_SOURCES\\NORMAL\"\n",
    "\n",
    "# create variable which stores all csv files\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "# create table headers with columns as keys and empty list for values\n",
    "table = {'feed_identifier': [], 'Considered to be Cached?': [], 'Caching Interval (secs)': []}\n",
    "\n",
    "# iterate through each file\n",
    "for f in csv_files:\n",
    "    \n",
    "    pattern = 'sources_(.*).csv'\n",
    "    \n",
    "    # set feed identifier as string in filename between sources_ and .csv\n",
    "    feed_identifier = re.search(pattern, f).group(1)\n",
    "    table[\"feed_identifier\"].append(feed_identifier)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # read csv into pandas dataframe\n",
    "        df = pd.read_csv(f)\n",
    "\n",
    "        # sort time_created in ascending order, convert dataframe to list\n",
    "        df.sort_values(by=['time_created'], ascending=True)\n",
    "        data = df.values.tolist()\n",
    "        \n",
    "        # create list just of time_created values. Use set() to find unique values\n",
    "        time_created = [d[2] for d in data]\n",
    "        time_created = list(set(time_created))\n",
    "        temp = []\n",
    "\n",
    "        # iterate through each time_created and create list of differences between each other value\n",
    "        for i in range(len(time_created)):\n",
    "            for j in range(i+1,len(time_created)):\n",
    "                if j!=i:\n",
    "                    temp.append(abs(time_created[i]-time_created[j]))\n",
    "        \n",
    "        # use set() to find unique differences\n",
    "        temp_unique = set(temp)\n",
    "        \n",
    "        # initialize cached to True\n",
    "        cached = True\n",
    "        \n",
    "        # remove 0 if exists as this is just the difference between the same creation times\n",
    "        if min(temp_unique)==0:\n",
    "            temp_unique.remove(0)\n",
    "\n",
    "        # find minimum value, this will be the lowest common denominator if caching exists     \n",
    "        min_ = min(temp_unique)\n",
    "        caching_interval = min_\n",
    "        \n",
    "        # iterate through differences, if any aren't exactly divisible by minimum value, caching doesn't exist\n",
    "        for t in temp:\n",
    "            if t%min_ != 0:\n",
    "                cached = False\n",
    "                caching_interval = 0\n",
    "\n",
    "        # set final condition of caching to be that minimum value (the caching interval) is >= 600\n",
    "        if cached == True and min_ <= 600:\n",
    "            cached = False\n",
    "            \n",
    "        # add caching status and interval values to table\n",
    "        table[\"Considered to be Cached?\"].append(cached)\n",
    "        table[\"Caching Interval (secs)\"].append(caching_interval)\n",
    "\n",
    "    except ValueError:\n",
    "        \n",
    "        # if there is a ValueError, which can be caused by unique creation time, caching doesn't exist\n",
    "        cached = False\n",
    "        caching_interval = 0\n",
    "        table[\"Considered to be Cached?\"].append(cached)\n",
    "        table[\"Caching Interval (secs)\"].append(caching_interval)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "filepath = Path(r\"YourFilepath\\companyx_normal.csv\")\n",
    "\n",
    "# convert table from dictionary to pandas dataframe\n",
    "df = pd.DataFrame.from_dict(table)\n",
    "\n",
    "# export table as file to given file path\n",
    "df.to_csv(filepath, index=False)          \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bad publish times**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "\n",
    "path = r\"YourFilepath\\RSSCacheDetection\\ACCOUNT_ARTICLE_SOURCES\\BAD_PUBLISH_TIME\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "table = {'feed_identifier': [], 'Considered to be Cached?': [], 'Caching Interval (secs)': []}\n",
    "  \n",
    "for f in csv_files:\n",
    "    \n",
    "    pattern = 'sources_(.*).csv'\n",
    "    feed_identifier = re.search(pattern, f).group(1)\n",
    "    table[\"feed_identifier\"].append(feed_identifier)\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "\n",
    "        df.sort_values(by=['time_created'], ascending=True)\n",
    "        data = df.values.tolist()\n",
    "        time_created = [d[2] for d in data]\n",
    "        time_created = list(set(time_created))\n",
    "        temp = []\n",
    "\n",
    "        for i in range(len(time_created)):\n",
    "            for j in range(i+1,len(time_created)):\n",
    "                if j!=i:\n",
    "                    temp.append(abs(time_created[i]-time_created[j]))\n",
    "\n",
    "        temp_unique = set(temp)\n",
    "            \n",
    "        cached = True\n",
    "        \n",
    "        if min(temp_unique)==0:\n",
    "            temp_unique.remove(0)\n",
    "\n",
    "        min_ = min(temp_unique)\n",
    "        caching_interval = min_\n",
    "        for t in temp:\n",
    "            if t%min_ != 0:\n",
    "                cached = False\n",
    "                caching_interval = 0\n",
    "\n",
    "        if cached == True and min_ <= 600:\n",
    "            cached = False\n",
    "            \n",
    "        table[\"Considered to be Cached?\"].append(cached)\n",
    "        table[\"Caching Interval (secs)\"].append(caching_interval)\n",
    "\n",
    "    except ValueError:\n",
    "        cached = False\n",
    "        caching_interval = 0\n",
    "        table[\"Considered to be Cached?\"].append(cached)\n",
    "        table[\"Caching Interval (secs)\"].append(caching_interval)\n",
    "\n",
    "from pathlib import Path  \n",
    "filepath = Path(r\"YourFilepath\\companyx_bad.csv\")  \n",
    "df = pd.DataFrame.from_dict(table)\n",
    "df.to_csv(filepath, index=False)          \n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
